"""
CLI Application ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö PIPELINE_SQLSERVER

‡πÅ‡∏≠‡∏õ‡∏û‡∏•‡∏¥‡πÄ‡∏Ñ‡∏ä‡∏±‡∏ô command line ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÑ‡∏ü‡∏•‡πå‡πÅ‡∏ö‡∏ö batch
"""

"""CLI Application ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö PIPELINE_SQLSERVER"""

import argparse
import logging
import os
from typing import Optional

from config.settings import settings_manager
from constants import AppConstants, PathConstants
from services.database_service import DatabaseService
from services.file_management_service import FileManagementService
from services.file_service import FileService

# ‡∏ó‡∏≥‡πÉ‡∏´‡πâ working directory ‡πÄ‡∏õ‡πá‡∏ô root ‡∏Ç‡∏≠‡∏á‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå‡πÄ‡∏™‡∏°‡∏≠
os.chdir(os.path.dirname(os.path.abspath(__file__)))

# Setup logging
logging.basicConfig(
    level=logging.INFO, 
    format=AppConstants.LOG_FORMAT
)

def load_last_path() -> Optional[str]:
    """
    ‡πÇ‡∏´‡∏•‡∏î search path ‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå last_path.json (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ö GUI)
    
    Returns:
        Optional[str]: search path ‡∏´‡∏£‡∏∑‡∏≠ None ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ
    """
    try:
        import json
        with open('config/last_path.json', 'r', encoding='utf-8') as f:
            data = json.load(f)
            return data.get('last_path', None)
    except (FileNotFoundError, json.JSONDecodeError, KeyError):
        return None

def process_file(file_path: str, file_service: FileService, db_service: DatabaseService) -> None:
    """
    ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏î‡∏µ‡∏¢‡∏ß: ‡∏≠‡πà‡∏≤‡∏ô ‡πÅ‡∏õ‡∏•‡∏á ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î ‡πÅ‡∏•‡∏∞‡∏¢‡πâ‡∏≤‡∏¢ (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô GUI)
    
    Args:
        file_path: ‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•
        file_service: ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÑ‡∏ü‡∏•‡πå
        db_service: ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    """
    try:
        logging.info(f"Processing file: {file_path}")
        # 1. ‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏ï‡∏£‡∏ß‡∏à logic_type ‡∏à‡∏≤‡∏Å header ‡∏Å‡πà‡∏≠‡∏ô (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô GUI)
        logic_type = file_service.detect_file_type(file_path)
        # 2. ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ ‡πÉ‡∏´‡πâ fallback ‡πÄ‡∏î‡∏≤‡∏à‡∏≤‡∏Å‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå
        if not logic_type:
            filename = os.path.basename(file_path)
            if hasattr(file_service, 'column_settings'):
                for key in file_service.column_settings.keys():
                    if key.lower() in filename.lower():
                        logic_type = key
                        break
        if not logic_type:
            logging.warning(f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏£‡∏∞‡∏ö‡∏∏‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÑ‡∏ü‡∏•‡πå (logic_type) ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö {os.path.basename(file_path)} ‡πÑ‡∏î‡πâ ‡∏Ç‡πâ‡∏≤‡∏°‡πÑ‡∏ü‡∏•‡πå‡∏ô‡∏µ‡πâ")
            return
        logging.info(f"Determined file type as: {logic_type}")
        # 3. ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô GUI)
        success, df_or_msg = file_service.read_excel_file(file_path, logic_type)
        if not success:
            logging.error(f"{df_or_msg}")
            return
        df = df_or_msg
        # 4. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô GUI)
        success, result = file_service.validate_columns(df, logic_type)
        if not success:
            logging.error(f"{result}")
            return
        required_cols = file_service.get_required_dtypes(logic_type)
        # 5. ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        success, message = db_service.upload_data(df, logic_type, required_cols)
        if success:
            logging.info(f"Successfully uploaded data from {file_path} to table for logic type {logic_type}.")
            # Move file after upload (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô GUI)
            move_success, move_result = file_service.move_uploaded_files([file_path], [logic_type])
            if move_success:
                for original_path, new_path in move_result:
                    logging.info(f"Moved file: {original_path} -> {new_path}")
            else:
                logging.error(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏¢‡πâ‡∏≤‡∏¢‡πÑ‡∏ü‡∏•‡πå: {move_result}")
        else:
            logging.error(f"Failed to upload data for {file_path}. Reason: {message}")
    except Exception as e:
        logging.error(f"An unexpected error occurred while processing {file_path}: {e}", exc_info=True)





def merge_zip_excel_cli(args) -> None:
    """
    ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏£‡∏ß‡∏°‡πÑ‡∏ü‡∏•‡πå Excel ‡∏à‡∏≤‡∏Å ZIP files
    
    Args:
        args: arguments ‡∏à‡∏≤‡∏Å argparse
    """
    logging.info("Starting ZIP Excel merger process.")
    
    file_mgmt_service = FileManagementService()
    
    if not os.path.exists(args.folder):
        logging.error(f"Folder does not exist: {args.folder}")
        return
    
    def progress_callback(value, status):
        """Callback ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏∑‡∏ö‡∏´‡∏ô‡πâ‡∏≤"""
        logging.info(f"Progress: {value*100:.1f}% - {status}")
    
    try:
        result = file_mgmt_service.process_zip_excel_merger(
            folder_path=args.folder,
            progress_callback=progress_callback
        )
        
        if result["success"]:
            logging.info("ZIP Excel merger completed successfully!")
            
            if result["saved_files"]:
                logging.info(f"Saved {len(result['saved_files'])} merged files:")
                for filename, rows in result["saved_files"]:
                    logging.info(f"  {filename}: {rows} rows")
            
            if result["organized_folder"] and result["moved_files"]:
                logging.info(f"Moved {len(result['moved_files'])} ZIP files to: {result['organized_folder']}")
        else:
            logging.error("ZIP Excel merger failed.")
            
        if result["errors"]:
            for error in result["errors"]:
                logging.error(f"Error during ZIP Excel merger: {error}")
        
    except Exception as e:
        logging.error(f"An error occurred during ZIP Excel merger: {e}", exc_info=True)


def validate_source_path() -> Optional[str]:
    """
    ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡πÇ‡∏´‡∏•‡∏î path ‡∏ï‡πâ‡∏ô‡∏ó‡∏≤‡∏á‡∏à‡∏≤‡∏Å last_path.json
    
    Returns:
        Optional[str]: path ‡∏ï‡πâ‡∏ô‡∏ó‡∏≤‡∏á‡∏´‡∏≤‡∏Å‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á, None ‡∏´‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á
    """
    last_path = load_last_path()
    if not last_path or not os.path.isdir(last_path):
        logging.error(f"‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ï‡πâ‡∏ô‡∏ó‡∏≤‡∏á‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ô last_path.json: {last_path}")
        logging.error("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ï‡πâ‡∏ô‡∏ó‡∏≤‡∏á‡πÉ‡∏ô config/last_path.json")
        return None
    
    logging.info(f"‡πÉ‡∏ä‡πâ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ï‡πâ‡∏ô‡∏ó‡∏≤‡∏á‡∏à‡∏≤‡∏Å last_path.json: {last_path}")
    return last_path


def process_zip_files_step(source_path: str) -> None:
    """
    ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 1: ‡∏£‡∏ß‡∏°‡πÑ‡∏ü‡∏•‡πå ZIP ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥ (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô _auto_process_zip_merger ‡πÉ‡∏ô GUI)
    
    Args:
        source_path (str): ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ï‡πâ‡∏ô‡∏ó‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå ZIP
    """
    logging.info("=== ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 1: ‡∏£‡∏ß‡∏°‡πÑ‡∏ü‡∏•‡πå ZIP ===")
    try:
        file_mgmt_service = FileManagementService()
        
        # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå ZIP ‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå (‡∏£‡∏ß‡∏° subfolder) ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô GUI
        zip_files = []
        for root, dirs, files in os.walk(source_path):
            for file in files:
                if file.lower().endswith('.zip'):
                    zip_files.append(os.path.join(root, file))
        
        if not zip_files:
            logging.info("‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå ZIP ‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ï‡πâ‡∏ô‡∏ó‡∏≤‡∏á ‡∏Ç‡πâ‡∏≤‡∏°‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ")
            return
        
        logging.info(f"‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå ZIP {len(zip_files)} ‡πÑ‡∏ü‡∏•‡πå ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏£‡∏ß‡∏°‡πÑ‡∏ü‡∏•‡πå Excel...")
        
        def progress_callback(value: float, status: str) -> None:
            logging.info(f"‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏∑‡∏ö‡∏´‡∏ô‡πâ‡∏≤: {value*100:.1f}% - {status}")
        
        result = file_mgmt_service.process_zip_excel_merger(
            folder_path=source_path,
            progress_callback=progress_callback
        )
        
        if result["success"]:
            logging.info("‚úÖ ‡∏£‡∏ß‡∏°‡πÑ‡∏ü‡∏•‡πå Excel ‡∏à‡∏≤‡∏Å ZIP ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô")
            if result["saved_files"]:
                for filename, rows in result["saved_files"]:
                    logging.info(f"  ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å: {filename} ({rows} ‡πÅ‡∏ñ‡∏ß)")
        else:
            logging.info("‚ö†Ô∏è ‡∏Å‡∏≤‡∏£‡∏£‡∏ß‡∏°‡πÑ‡∏ü‡∏•‡πå ZIP ‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à ‡πÅ‡∏ï‡πà‡∏à‡∏∞‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡πà‡∏≠")
            
        if result["errors"]:
            for error in result["errors"]:
                logging.info(f"‚ö†Ô∏è ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô ZIP merger: {error}")
                
    except Exception as e:
        logging.error(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏£‡∏ß‡∏°‡πÑ‡∏ü‡∏•‡πå ZIP: {e}")
        logging.info("‡∏à‡∏∞‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡πà‡∏≠‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÑ‡∏ü‡∏•‡πå‡∏´‡∏•‡∏±‡∏Å")


def process_main_files_step(source_path: str) -> None:
    """
    ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 2: ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÑ‡∏ü‡∏•‡πå‡∏´‡∏•‡∏±‡∏Å‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥ (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô _auto_process_main_files ‡πÉ‡∏ô GUI)
    
    Args:
        source_path (str): ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ï‡πâ‡∏ô‡∏ó‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå
    """
    logging.info("=== ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 2: ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÑ‡∏ü‡∏•‡πå‡∏´‡∏•‡∏±‡∏Å ===")
    
    try:
        # ‡πÉ‡∏ä‡πâ logging.info ‡πÄ‡∏õ‡πá‡∏ô log_callback ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö CLI (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô GUI)
        file_service = FileService(search_path=source_path, log_callback=logging.info)
        db_service = DatabaseService()

        # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        data_files = file_service.find_data_files()
        
        if not data_files:
            logging.info("‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ï‡πâ‡∏ô‡∏ó‡∏≤‡∏á")
            return
        
        logging.info(f"‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• {len(data_files)} ‡πÑ‡∏ü‡∏•‡πå ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•...")
        
        total_files = len(data_files)
        processed_files = 0
        successful_uploads = 0
        
        for file_path in data_files:
            try:
                processed_files += 1
                
                logging.info(f"üìÅ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•: {os.path.basename(file_path)} ({processed_files}/{total_files})")
                
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏´‡∏≤ logic_type (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô GUI)
                logic_type = file_service.detect_file_type(file_path)
                if not logic_type:
                    # ‡∏•‡∏≠‡∏á‡πÄ‡∏î‡∏≤‡∏à‡∏≤‡∏Å‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô GUI)
                    filename = os.path.basename(file_path).lower()
                    for key in file_service.column_settings.keys():
                        if key.lower() in filename:
                            logic_type = key
                            break
                
                if not logic_type:
                    logging.info(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏£‡∏∞‡∏ö‡∏∏‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÑ‡∏ü‡∏•‡πå: {os.path.basename(file_path)}")
                    continue
                
                logging.info(f"üìã ‡∏£‡∏∞‡∏ö‡∏∏‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÑ‡∏ü‡∏•‡πå: {logic_type}")
                
                # ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô GUI)
                success, result = file_service.read_excel_file(file_path, logic_type)
                if not success:
                    logging.info(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå: {result}")
                    continue
                
                df = result
                
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô GUI)
                success, result = file_service.validate_columns(df, logic_type)
                if not success:
                    logging.info(f"‚ùå ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á: {result}")
                    continue
                
                # ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô GUI)
                required_cols = file_service.get_required_dtypes(logic_type)
                
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ required_cols ‡πÑ‡∏°‡πà‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏õ‡∏•‡πà‡∏≤
                if not required_cols:
                    logging.info(f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö {logic_type}")
                    continue
                
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏õ‡∏•‡πà‡∏≤
                if df.empty:
                    logging.info(f"‚ùå ‡πÑ‡∏ü‡∏•‡πå {os.path.basename(file_path)} ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
                    continue
                
                logging.info(f"üìä ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• {len(df)} ‡πÅ‡∏ñ‡∏ß ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó {logic_type}")
                success, message = db_service.upload_data(df, logic_type, required_cols, log_func=logging.info)
                
                if success:
                    logging.info(f"‚úÖ ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {message}")
                    successful_uploads += 1
                    
                    # ‡∏¢‡πâ‡∏≤‡∏¢‡πÑ‡∏ü‡∏•‡πå‡∏´‡∏•‡∏±‡∏á‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô GUI)
                    try:
                        move_success, move_result = file_service.move_uploaded_files([file_path], [logic_type])
                        if move_success:
                            for original_path, new_path in move_result:
                                logging.info(f"üì¶ ‡∏¢‡πâ‡∏≤‡∏¢‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏õ‡∏¢‡∏±‡∏á: {os.path.basename(new_path)}")
                        else:
                            logging.info(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏¢‡πâ‡∏≤‡∏¢‡πÑ‡∏ü‡∏•‡πå: {move_result}")
                    except Exception as move_error:
                        logging.info(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏¢‡πâ‡∏≤‡∏¢‡πÑ‡∏ü‡∏•‡πå: {move_error}")
                else:
                    logging.info(f"‚ùå ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {message}")
                    # ‡∏•‡∏≠‡∏á‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö error ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏° (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô GUI)
                    logging.info(f"üîç ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: ‡πÅ‡∏ñ‡∏ß {len(df)}, ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå {list(df.columns)}")
                    
            except Exception as e:
                logging.info(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏Ç‡∏ì‡∏∞‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• {os.path.basename(file_path)}: {e}")
        
        logging.info(f"‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô: {successful_uploads}/{total_files} ‡πÑ‡∏ü‡∏•‡πå‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
        
    except Exception as e:
        logging.error(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÑ‡∏ü‡∏•‡πå: {e}", exc_info=True)





def main_cli() -> None:
    """
    ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö CLI application - ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô GUI
    
    ‡∏£‡∏±‡∏ô‡∏ï‡∏≤‡∏°‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô:
    1. ‡∏£‡∏ß‡∏°‡πÑ‡∏ü‡∏•‡πå Excel ‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå ZIP
    2. ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡∏∞‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
    """
    logging.info("ü§ñ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥")

    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡πÇ‡∏´‡∏•‡∏î path ‡∏ï‡πâ‡∏ô‡∏ó‡∏≤‡∏á
    source_path = validate_source_path()
    if not source_path:
        return
    
    logging.info(f"üìÇ ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ï‡πâ‡∏ô‡∏ó‡∏≤‡∏á: {source_path}")
    
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡πà‡∏≠‡∏ô (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô GUI)
    db_service = DatabaseService()
    is_connected, message = db_service.check_connection()
    if not is_connected:
        logging.error(f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏î‡πâ: {message}")
        logging.error("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡πà‡∏≠‡∏ô")
        return

    try:
        # ‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏≤‡∏°‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô
        process_zip_files_step(source_path)
        process_main_files_step(source_path)
        
        logging.info("=== üèÅ ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô ===")
        
    except Exception as e:
        logging.error(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥: {e}", exc_info=True)


def main():
    """‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏´‡∏•‡∏±‡∏Å‡∏ó‡∏µ‡πà‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ command line arguments"""
    parser = argparse.ArgumentParser(
        description='PIPELINE_SQLSERVER CLI - ‡πÅ‡∏≠‡∏õ‡∏û‡∏•‡∏¥‡πÄ‡∏Ñ‡∏ä‡∏±‡∏ô command line ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÑ‡∏ü‡∏•‡πå',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô:

  # ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÑ‡∏ü‡∏•‡πå‡∏õ‡∏Å‡∏ï‡∏¥ (default)
  python pipeline_cli_app.py

  # ‡∏£‡∏ß‡∏°‡πÑ‡∏ü‡∏•‡πå Excel ‡∏à‡∏≤‡∏Å ZIP files
  python pipeline_cli_app.py merge-zip --folder ./path/to/zip/folder
        """
    )
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á subcommands
    subparsers = parser.add_subparsers(dest='command', help='‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ')
    

    
    # Subcommand ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö ZIP Excel merger
    merge_parser = subparsers.add_parser(
        'merge-zip', 
        help='‡∏£‡∏ß‡∏°‡πÑ‡∏ü‡∏•‡πå Excel ‡∏à‡∏≤‡∏Å ZIP files'
    )
    merge_parser.add_argument(
        '--folder', 
        type=str, 
        required=True, 
        help='‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÑ‡∏ü‡∏•‡πå ZIP (‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏∞‡∏ö‡∏∏)'
    )
    
    args = parser.parse_args()
    
    # ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ï‡∏≤‡∏° command ‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å
    if args.command == 'merge-zip':
        merge_zip_excel_cli(args)
    else:
        # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ command ‡∏´‡∏£‡∏∑‡∏≠ command ‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á ‡πÉ‡∏´‡πâ‡∏£‡∏±‡∏ô‡πÅ‡∏ö‡∏ö‡∏õ‡∏Å‡∏ï‡∏¥
        main_cli()


if __name__ == '__main__':
    main()
