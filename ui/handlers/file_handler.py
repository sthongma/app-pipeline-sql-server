"""File Operation Handlers"""
import os
import threading
import time
from datetime import datetime
from tkinter import messagebox, filedialog
import pandas as pd


class FileHandler:
    def __init__(self, file_service, db_service, file_mgmt_service, log_callback):
        """
        Initialize File Handler
        
        Args:
            file_service: File service instance
            db_service: Database service instance
            file_mgmt_service: File management service instance
            log_callback: Function to call for logging
        """
        self.file_service = file_service
        self.db_service = db_service
        self.file_mgmt_service = file_mgmt_service
        self.log = log_callback
    
    def browse_excel_path(self, save_callback):
        """‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå"""
        folder = filedialog.askdirectory()
        if folder:
            self.file_service.set_search_path(folder)
            save_callback(folder)
            messagebox.showinfo("Success", f"Set search path for Excel files to\n{folder}")
    
    def run_check_thread(self, ui_callbacks):
        """‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏ô thread ‡πÅ‡∏¢‡∏Å"""
        thread = threading.Thread(target=self._check_files, args=(ui_callbacks,))
        thread.start()
    
    def _check_files(self, ui_callbacks):
        """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏ô Path ‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î"""
        try:
            # ‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï UI
            ui_callbacks['reset_progress']()
            ui_callbacks['set_progress_status']("Starting file scan", "Scanning folders...")
            
            # ‡πÇ‡∏´‡∏•‡∏î‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÉ‡∏´‡∏°‡πà
            self.file_service.load_settings()
            ui_callbacks['clear_file_list']()
            ui_callbacks['disable_auto_process']()
            ui_callbacks['reset_select_all']()
            
            # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå Excel/CSV
            ui_callbacks['update_progress'](0.2, "Searching for files", "Scanning .xlsx and .csv files...")
            data_files = self.file_service.find_data_files()
            
            if not data_files:
                ui_callbacks['update_progress'](1.0, "Scan completed", "No .xlsx or .csv files found")
                ui_callbacks['update_status']("No .xlsx or .csv files found in the specified folder", True)
                self.log("ü§∑ No .xlsx or .csv files found in the specified folder")
                self.log("--- üèÅ File scan completed ---")
                ui_callbacks['enable_auto_process']()
                return
            
            found_files_count = 0
            total_files = len(data_files)
            
            for i, file in enumerate(data_files):
                # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì progress ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á (0.2 - 0.8)
                progress = 0.2 + (0.6 * (i / total_files))  # 20% - 80%
                ui_callbacks['update_progress'](progress, f"Checking file: {os.path.basename(file)}", f"File {i+1} of {total_files}")
                
                logic_type = self.file_service.detect_file_type(file)
                if logic_type:
                    found_files_count += 1
                    self.log(f"‚úÖ Found matching file: {os.path.basename(file)} [{logic_type}]")
                    ui_callbacks['add_file_to_list'](file, logic_type)
            
            if found_files_count > 0:
                ui_callbacks['update_progress'](1.0, "Scan completed", f"Found {found_files_count} matching files")
                ui_callbacks['update_status'](f"Found {found_files_count} matching files", False)
                ui_callbacks['enable_select_all']()
            else:
                ui_callbacks['update_progress'](1.0, "Scan completed", "No matching files found")
                ui_callbacks['update_status']("No matching files found", True)
                ui_callbacks['reset_select_all']()
            
            self.log("--- üèÅ File scan completed ---")
            ui_callbacks['enable_auto_process']()
            
        except Exception as e:
            self.log(f"‚ùå An error occurred while scanning files: {e}")
            ui_callbacks['enable_auto_process']()
    
    def confirm_upload(self, get_selected_files_callback, ui_callbacks):
        """‡∏¢‡∏∑‡∏ô‡∏¢‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å"""
        selected = get_selected_files_callback()
        if not selected:
            messagebox.showwarning("No files", "Please select files to upload")
            return
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        success, message = self.db_service.check_connection()
        if not success:
            messagebox.showerror(
                "Error", 
                f"Cannot connect to database:\n{message}\n\nPlease check database settings first"
            )
            return
            
            
            
        answer = messagebox.askyesno(
            "Confirm Upload",
            f"Are you sure you want to upload the selected {len(selected)} files?"
        )
        
        if answer:
            ui_callbacks['reset_progress']()
            ui_callbacks['disable_controls']()
            thread = threading.Thread(target=self._upload_selected_files, args=(selected, ui_callbacks))
            thread.start()
    
    def _upload_selected_files(self, selected_files, ui_callbacks):
        """‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏õ‡∏¢‡∏±‡∏á SQL Server"""
        # ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏à‡∏±‡∏ö‡πÄ‡∏ß‡∏•‡∏≤
        upload_start_time = time.time()
        
        # ‡∏à‡∏±‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏°‡πÑ‡∏ü‡∏•‡πå‡∏ï‡∏≤‡∏° logic_type
        files_by_type = {}
        for (file_path, logic_type), chk in selected_files:
            if logic_type not in files_by_type:
                files_by_type[logic_type] = []
            files_by_type[logic_type].append((file_path, chk))
        
        total_types = len(files_by_type)
        completed_types = 0
        total_files = sum(len(files) for files in files_by_type.values())
        processed_files = 0
        
        # ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î
        upload_stats = {
            'total_start_time': upload_start_time,
            'by_type': {},
            'errors': [],
            'successful_files': 0,
            'failed_files': 0
        }
        
        # ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô
        ui_callbacks['set_progress_status']("Starting upload", f"Found {total_files} files from {total_types} types")
        
        # Phase 1: Read and validate all files first
        self.log("üìñ Phase 1: Reading and validating all files...")
        all_validated_data = {}  # {logic_type: (combined_df, files_info, required_cols)}
        
        for logic_type, files in files_by_type.items():
            try:
                # ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏à‡∏±‡∏ö‡πÄ‡∏ß‡∏•‡∏≤‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÑ‡∏ü‡∏•‡πå‡∏ô‡∏µ‡πâ
                type_start_time = time.time()
                upload_stats['by_type'][logic_type] = {
                    'start_time': type_start_time,
                    'files_count': len(files),
                    'successful_files': 0,
                    'failed_files': 0,
                    'errors': []
                }
                
                self.log(f"üìñ Validating files of type {logic_type}")
                
                # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï Progress Bar ‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏∑‡∏ö‡∏´‡∏ô‡πâ‡∏≤
                progress = completed_types / total_types
                ui_callbacks['update_progress'](progress, f"Validating type {logic_type}", f"Type {completed_types + 1} of {total_types}")
                
                # ‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏ó‡∏∏‡∏Å‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏ô‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô
                all_dfs = []
                valid_files_info = []
                
                for file_path, chk in files:
                    try:
                        processed_files += 1
                        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì progress ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á (0.0 - 1.0)
                        file_progress = (processed_files - 1) / total_files  # ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏à‡∏≤‡∏Å 0
                        
                        # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏∑‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏£‡∏∞‡∏î‡∏±‡∏ö‡πÑ‡∏ü‡∏•‡πå
                        ui_callbacks['update_progress'](file_progress, f"Checking columns: {os.path.basename(file_path)}", f"File {processed_files} of {total_files}")
                        
                        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏Å‡πà‡∏≠‡∏ô‡πÇ‡∏î‡∏¢‡∏Å‡∏≤‡∏£ preview ‡πÑ‡∏ü‡∏•‡πå (‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î‡πÄ‡∏ß‡∏•‡∏≤)
                        success, result, columns_info = self.file_service.preview_file_columns(file_path, logic_type)
                        if not success:
                            self.log(f"‚ùå Column check failed for {os.path.basename(file_path)}: {result}")
                            upload_stats['by_type'][logic_type]['failed_files'] += 1
                            upload_stats['by_type'][logic_type]['errors'].append(f"{os.path.basename(file_path)}: {result}")
                            upload_stats['failed_files'] += 1
                            continue
                        
                        # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏∑‡∏ö‡∏´‡∏ô‡πâ‡∏≤ - ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ú‡πà‡∏≤‡∏ô‡πÅ‡∏•‡πâ‡∏ß
                        ui_callbacks['update_progress'](file_progress, f"Columns OK, reading file: {os.path.basename(file_path)}", f"File {processed_files} of {total_files}")
                        
                        # ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏ï‡πá‡∏°‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö (‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ú‡πà‡∏≤‡∏ô‡πÅ‡∏•‡πâ‡∏ß)
                        success, result = self.file_service.read_excel_file(file_path, logic_type)
                        if not success:
                            self.log(f"‚ùå Failed to read file {os.path.basename(file_path)}: {result}")
                            upload_stats['by_type'][logic_type]['failed_files'] += 1
                            upload_stats['by_type'][logic_type]['errors'].append(f"{os.path.basename(file_path)}: {result}")
                            upload_stats['failed_files'] += 1
                            continue
                        
                        df = result
                        
                        # ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏: ‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏à‡∏∞‡∏ó‡∏≥‡πÉ‡∏ô staging table ‡∏î‡πâ‡∏ß‡∏¢ SQL
                        # ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÑ‡∏î‡πâ‡∏ñ‡∏π‡∏Å‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡πâ‡∏ß‡∏î‡πâ‡∏ß‡∏¢ preview_file_columns()
                        
                        all_dfs.append(df)
                        valid_files_info.append((file_path, chk))
                        upload_stats['by_type'][logic_type]['successful_files'] += 1
                        self.log(f"‚úÖ File validated and ready: {os.path.basename(file_path)}")
                        
                    except Exception as e:
                        error_msg = f"An error occurred while reading file {os.path.basename(file_path)}: {e}"
                        self.log(f"‚ùå {error_msg}")
                        upload_stats['by_type'][logic_type]['failed_files'] += 1
                        upload_stats['by_type'][logic_type]['errors'].append(f"{os.path.basename(file_path)}: {str(e)}")
                        upload_stats['failed_files'] += 1
                
                if not all_dfs:
                    self.log(f"‚ùå No valid data from files of type {logic_type}")
                    completed_types += 1
                    continue
                
                # ‡∏£‡∏ß‡∏° DataFrame ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
                combined_df = pd.concat(all_dfs, ignore_index=True)
                
                # ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Å‡∏≤‡∏£‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
                ui_callbacks['update_progress'](file_progress, f"Combining data for type {logic_type}", f"Combined {len(all_dfs)} files into {len(combined_df)} rows")
                
                # ‡πÉ‡∏ä‡πâ dtype ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á
                required_cols = self.file_service.get_required_dtypes(logic_type)
                
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ required_cols ‡πÑ‡∏°‡πà‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏õ‡∏•‡πà‡∏≤
                if not required_cols:
                    self.log(f"‚ùå No data type configuration found for {logic_type}")
                    completed_types += 1
                    continue
                
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏õ‡∏•‡πà‡∏≤
                if combined_df.empty:
                    self.log(f"‚ùå No valid data from files of type {logic_type}")
                    completed_types += 1
                    continue
                
                # ‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ú‡πà‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡πâ‡∏ß
                all_validated_data[logic_type] = (combined_df, valid_files_info, required_cols)
                self.log(f"‚úÖ Prepared {len(combined_df)} rows for type {logic_type}")
                    
                completed_types += 1
                # ‡∏à‡∏±‡∏ö‡πÄ‡∏ß‡∏•‡∏≤‡∏™‡πà‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß ‡πÅ‡∏ï‡πà‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏£‡∏ß‡∏°‡∏Å‡∏≤‡∏£‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î
                upload_stats['by_type'][logic_type]['reading_time'] = time.time() - type_start_time
                
            except Exception as e:
                error_msg = f"An error occurred while validating files of type {logic_type}: {e}"
                self.log(f"‚ùå {error_msg}")
                upload_stats['by_type'][logic_type]['errors'].append(error_msg)
                upload_stats['by_type'][logic_type]['reading_time'] = time.time() - type_start_time
                completed_types += 1
        
        # Phase 2: Upload all validated data (with proper table clearing sequence)
        if all_validated_data:
            self.log("üì§ Phase 2: Uploading all validated data...")
            upload_count = 0
            total_uploads = len(all_validated_data)
            
            for logic_type, (combined_df, valid_files_info, required_cols) in all_validated_data.items():
                try:
                    upload_progress = upload_count / total_uploads
                    ui_callbacks['update_progress'](upload_progress, f"Uploading data for type {logic_type}", f"Upload {upload_count + 1} of {total_uploads}")
                    
                    self.log(f"üìä Uploading {len(combined_df)} rows for type {logic_type}")
                    
                    # Clear existing data only for the first upload of each table
                    success, message = self.db_service.upload_data(
                        combined_df, logic_type, required_cols, 
                        log_func=self.log, clear_existing=True
                    )
                    
                    if success:
                        self.log(f"‚úÖ {message}")
                        upload_stats['successful_files'] += len(valid_files_info)
                        for file_path, chk in valid_files_info:
                            ui_callbacks['disable_checkbox'](chk)
                            ui_callbacks['set_file_uploaded'](file_path)
                            # ‡∏¢‡πâ‡∏≤‡∏¢‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏±‡∏ô‡∏ó‡∏µ‡∏´‡∏•‡∏±‡∏á‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à
                            try:
                                move_success, move_result = self.file_service.move_uploaded_files([file_path], [logic_type])
                                if move_success:
                                    for original_path, new_path in move_result:
                                        self.log(f"üì¶ Moved file to: {os.path.basename(new_path)}")
                                else:
                                    self.log(f"‚ùå Could not move file: {move_result}")
                            except Exception as move_error:
                                self.log(f"‚ùå An error occurred while moving file: {move_error}")
                    else:
                        # ‡πÅ‡∏™‡∏î‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏£‡∏∏‡∏õ‡∏à‡∏≤‡∏Å‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡πÑ‡∏°‡πà‡∏û‡∏¥‡∏°‡∏û‡πå‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
                        self.log(f"‚ùå {message}")
                        upload_stats['by_type'][logic_type]['errors'].append(f"Database upload failed: {message}")
                        upload_stats['failed_files'] += len(valid_files_info)
                        
                    upload_count += 1
                    
                    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÄ‡∏ß‡∏•‡∏≤‡∏£‡∏ß‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÑ‡∏ü‡∏•‡πå‡∏ô‡∏µ‡πâ (‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå + ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î)
                    if 'start_time' in upload_stats['by_type'][logic_type]:
                        upload_stats['by_type'][logic_type]['processing_time'] = time.time() - upload_stats['by_type'][logic_type]['start_time']
                    
                except Exception as e:
                    error_msg = f"An error occurred while uploading data for type {logic_type}: {e}"
                    self.log(f"‚ùå {error_msg}")
                    upload_stats['by_type'][logic_type]['errors'].append(error_msg)
                    upload_count += 1
                    
                    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÄ‡∏ß‡∏•‡∏≤‡∏£‡∏ß‡∏°‡πÅ‡∏°‡πâ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î
                    if 'start_time' in upload_stats['by_type'][logic_type]:
                        upload_stats['by_type'][logic_type]['processing_time'] = time.time() - upload_stats['by_type'][logic_type]['start_time']
        else:
            self.log("‚ùå No validated data to upload")
        
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÄ‡∏ß‡∏•‡∏≤‡∏£‡∏ß‡∏°
        total_upload_time = time.time() - upload_start_time
        upload_stats['total_time'] = total_upload_time
        
        # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï progress ‡πÄ‡∏õ‡πá‡∏ô 100% ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô
        ui_callbacks['update_progress'](1.0, "Upload completed", f"Processed {total_files} files successfully")
        
        # ‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏™‡∏£‡∏∏‡∏õ
        self._display_upload_summary(upload_stats, total_files)
        
        # ‡πÄ‡∏õ‡∏¥‡∏î‡∏õ‡∏∏‡πà‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏Å‡∏•‡∏±‡∏ö‡∏°‡∏≤
        ui_callbacks['enable_controls']()
    
    def _display_upload_summary(self, upload_stats, total_files):
        """‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏™‡∏£‡∏∏‡∏õ‡∏Å‡∏≤‡∏£‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î"""
        self.log("========= Upload Summary Report ==========")
        
        # ‡πÄ‡∏ß‡∏•‡∏≤‡∏£‡∏ß‡∏°
        total_time = upload_stats.get('total_time', 0)
        hours = int(total_time // 3600)
        minutes = int((total_time % 3600) // 60)
        seconds = int(total_time % 60)
        
        if hours > 0:
            time_str = f"{hours}h {minutes}m {seconds}s"
        elif minutes > 0:
            time_str = f"{minutes}m {seconds}s"
        else:
            time_str = f"{seconds}s"
        
        self.log(f"üìä Total Upload Time: {time_str}")
        self.log(f"üìÅ Total Files Processed: {total_files}")
        self.log(f"‚úÖ Successful: {upload_stats.get('successful_files', 0)}")
        self.log(f"‚ùå Failed: {upload_stats.get('failed_files', 0)}")
        
        # ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÑ‡∏ü‡∏•‡πå
        if upload_stats.get('by_type'):
            self.log("")
            self.log("üìã Details by File Type:")
            self.log("-" * 50)
            
            for file_type, stats in upload_stats['by_type'].items():
                type_time = stats.get('processing_time', 0)
                type_hours = int(type_time // 3600)
                type_minutes = int((type_time % 3600) // 60)
                type_seconds = int(type_time % 60)
                
                if type_hours > 0:
                    type_time_str = f"{type_hours}h {type_minutes}m {type_seconds}s"
                elif type_minutes > 0:
                    type_time_str = f"{type_minutes}m {type_seconds}s"
                else:
                    type_time_str = f"{type_seconds}s"
                
                self.log(f"üè∑Ô∏è  {file_type}:")
                self.log(f"   ‚è±Ô∏è  Processing Time: {type_time_str}")
                self.log(f"   üìÇ Total Files: {stats.get('files_count', 0)}")
                self.log(f"   ‚úÖ Successful: {stats.get('successful_files', 0)}")
                self.log(f"   ‚ùå Failed: {stats.get('failed_files', 0)}")
                
                # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)
                errors = stats.get('errors', [])
                if errors:
                    self.log(f"   üö® Errors ({len(errors)}):")
                    for i, error in enumerate(errors[:3], 1):  # ‡πÅ‡∏™‡∏î‡∏á‡πÅ‡∏Ñ‡πà 3 ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÅ‡∏£‡∏Å
                        self.log(f"      {i}. {error}")
                    if len(errors) > 3:
                        self.log(f"      ... ‡πÅ‡∏•‡∏∞‡∏≠‡∏µ‡∏Å {len(errors) - 3} ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î")
                self.log("")
        
        # ‡∏™‡∏£‡∏∏‡∏õ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç
        success_rate = 0
        if total_files > 0:
            success_rate = (upload_stats.get('successful_files', 0) / total_files) * 100
        
        self.log("üìà Summary:")
        self.log(f"   Success Rate: {success_rate:.1f}%")
        
        if upload_stats.get('failed_files', 0) > 0:
            self.log("   ‚ö†Ô∏è  Some files failed to upload. Check the errors above for details.")
        else:
            self.log("   üéâ All files uploaded successfully!")
        
        self.log("=========================================")
    
    def _display_auto_process_summary(self, process_stats, total_files):
        """‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏™‡∏£‡∏∏‡∏õ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥"""
        self.log("======= Auto Process Summary Report =======")
        
        # ‡πÄ‡∏ß‡∏•‡∏≤‡∏£‡∏ß‡∏°
        total_time = process_stats.get('total_time', 0)
        hours = int(total_time // 3600)
        minutes = int((total_time % 3600) // 60)
        seconds = int(total_time % 60)
        
        if hours > 0:
            time_str = f"{hours}h {minutes}m {seconds}s"
        elif minutes > 0:
            time_str = f"{minutes}m {seconds}s"
        else:
            time_str = f"{seconds}s"
        
        self.log(f"üìä Total Processing Time: {time_str}")
        self.log(f"üìÅ Total Files Processed: {total_files}")
        self.log(f"‚úÖ Successful: {process_stats.get('successful_files', 0)}")
        self.log(f"‚ùå Failed: {process_stats.get('failed_files', 0)}")
        
        # ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÑ‡∏ü‡∏•‡πå
        if process_stats.get('by_type'):
            self.log("")
            self.log("üìã Details by File Type:")
            self.log("-" * 50)
            
            for file_type, stats in process_stats['by_type'].items():
                type_time = stats.get('processing_time', 0)
                type_hours = int(type_time // 3600)
                type_minutes = int((type_time % 3600) // 60)
                type_seconds = int(type_time % 60)
                
                if type_hours > 0:
                    type_time_str = f"{type_hours}h {type_minutes}m {type_seconds}s"
                elif type_minutes > 0:
                    type_time_str = f"{type_minutes}m {type_seconds}s"
                else:
                    type_time_str = f"{type_seconds}s"
                
                self.log(f"üè∑Ô∏è  {file_type}:")
                self.log(f"   ‚è±Ô∏è  Processing Time: {type_time_str}")
                self.log(f"   üìÇ Total Files: {stats.get('files_count', 0)}")
                self.log(f"   ‚úÖ Successful: {stats.get('successful_files', 0)}")
                self.log(f"   ‚ùå Failed: {stats.get('failed_files', 0)}")
                
                # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)
                errors = stats.get('errors', [])
                if errors:
                    self.log(f"   üö® Errors ({len(errors)}):")
                    for i, error in enumerate(errors[:3], 1):  # ‡πÅ‡∏™‡∏î‡∏á‡πÅ‡∏Ñ‡πà 3 ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÅ‡∏£‡∏Å
                        self.log(f"      {i}. {error}")
                    if len(errors) > 3:
                        self.log(f"      ... ‡πÅ‡∏•‡∏∞‡∏≠‡∏µ‡∏Å {len(errors) - 3} ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î")
                self.log("")
        
        # ‡∏™‡∏£‡∏∏‡∏õ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç
        success_rate = 0
        if total_files > 0:
            success_rate = (process_stats.get('successful_files', 0) / total_files) * 100
        
        self.log("üìà Summary:")
        self.log(f"   Success Rate: {success_rate:.1f}%")
        
        if process_stats.get('failed_files', 0) > 0:
            self.log("   ‚ö†Ô∏è  Some files failed to process. Check the errors above for details.")
        else:
            self.log("   üéâ All files processed successfully!")
        
        self.log("==========================================")
    
    def start_auto_process(self, load_last_path_callback, column_settings):
        """‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥ (‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÑ‡∏ü‡∏•‡πå)"""
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ï‡πâ‡∏ô‡∏ó‡∏≤‡∏á‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
        last_path = load_last_path_callback()
        if not last_path or not os.path.isdir(last_path):
            messagebox.showerror(
                "Error", 
                f"Invalid source folder: {last_path}\n\nPlease select a source folder first"
            )
            return
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        success, message = self.db_service.check_connection()
        if not success:
            messagebox.showerror(
                "Error", 
                f"Cannot connect to database:\n{message}\n\nPlease check database settings first"
            )
            return
            
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÑ‡∏ü‡∏•‡πå
        if not column_settings:
            messagebox.showerror(
                "Error", 
                "No file type configuration found\n\nPlease go to Settings tab and add file types first"
            )
            return
        
        # ‡∏¢‡∏∑‡∏ô‡∏¢‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô
        result = messagebox.askyesno(
            "Confirm Auto Processing",
            f"Will perform auto processing in folder:\n{last_path}\n\n"
            "Processing steps:\n"
            "1. Find all data files\n"
            "2. Process and upload all files\n"
            "Do you want to proceed?"
        )
        
        if not result:
            return
        
        return last_path  # Return path for further processing
    
    def run_auto_process(self, folder_path, ui_callbacks):
        """‡∏£‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥‡πÉ‡∏ô thread ‡πÅ‡∏¢‡∏Å"""
        try:
            # ‡∏õ‡∏¥‡∏î‡∏õ‡∏∏‡πà‡∏°‡∏ï‡πà‡∏≤‡∏á‡πÜ ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô
            ui_callbacks['disable_controls']()
            
            # ‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï progress bar ‡πÅ‡∏•‡∏∞‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô
            ui_callbacks['reset_progress']()
            ui_callbacks['set_progress_status']("Starting auto processing", "Preparing system...")
            
            self.log("ü§ñ Starting auto processing")
            self.log(f"üìÇ Source folder: {folder_path}")
            
            # === ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÑ‡∏ü‡∏•‡πå‡∏´‡∏•‡∏±‡∏Å ===
            self.log("========= Processing files ==========")
            self._auto_process_main_files(folder_path, ui_callbacks)
            
            self.log("==== Auto processing completed ======") 
            ui_callbacks['update_progress'](1.0, "Auto processing completed", "All steps completed successfully")
            messagebox.showinfo("Success", "Auto processing completed successfully")
            
        except Exception as e:
            self.log(f"‚ùå An error occurred during auto processing: {e}")
            messagebox.showerror("Error", f"An error occurred: {e}")
        finally:
            # ‡πÄ‡∏õ‡∏¥‡∏î‡∏õ‡∏∏‡πà‡∏°‡∏Å‡∏•‡∏±‡∏ö‡∏°‡∏≤
            ui_callbacks['enable_controls']()
    
    def _auto_process_main_files(self, folder_path, ui_callbacks):
        """‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÑ‡∏ü‡∏•‡πå‡∏´‡∏•‡∏±‡∏Å‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥"""
        try:
            # ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏à‡∏±‡∏ö‡πÄ‡∏ß‡∏•‡∏≤
            process_start_time = time.time()
            
            # ‡∏ï‡∏±‡πâ‡∏á search path ‡πÉ‡∏´‡∏°‡πà
            self.file_service.set_search_path(folder_path)
            
            # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
            data_files = self.file_service.find_data_files()
            
            if not data_files:
                self.log("No data files found in source folder")
                return
            
            self.log(f"Found {len(data_files)} data files, starting processing...")
            
            total_files = len(data_files)
            processed_files = 0
            successful_uploads = 0
            
            # ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•
            process_stats = {
                'start_time': process_start_time,
                'by_type': {},
                'errors': [],
                'successful_files': 0,
                'failed_files': 0
            }
            
            for file_path in data_files:
                try:
                    processed_files += 1
                    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì progress ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á (0.0 - 1.0)
                    progress = (processed_files - 1) / total_files  # ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏à‡∏≤‡∏Å 0
                    
                    # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏∑‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÅ‡∏ö‡∏ö‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î
                    ui_callbacks['update_progress'](progress, f"Processing file: {os.path.basename(file_path)}", f"File {processed_files} of {total_files}")
                    
                    self.log(f"üìÅ Processing file: {os.path.basename(file_path)}")
                    
                    # ‡∏ï‡∏£‡∏ß‡∏à‡∏´‡∏≤ logic_type
                    logic_type = self.file_service.detect_file_type(file_path)
                    if not logic_type:
                        # ‡∏•‡∏≠‡∏á‡πÄ‡∏î‡∏≤‡∏à‡∏≤‡∏Å‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå
                        filename = os.path.basename(file_path).lower()
                        for key in self.file_service.column_settings.keys():
                            if key.lower() in filename:
                                logic_type = key
                                break
                    
                    if not logic_type:
                        error_msg = f"Could not identify file type: {os.path.basename(file_path)}"
                        self.log(f"‚ùå {error_msg}")
                        process_stats['failed_files'] += 1
                        process_stats['errors'].append(f"{os.path.basename(file_path)}: {error_msg}")
                        continue
                    
                    # ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏à‡∏±‡∏ö‡πÄ‡∏ß‡∏•‡∏≤‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÑ‡∏ü‡∏•‡πå‡∏ô‡∏µ‡πâ (‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ)
                    if logic_type not in process_stats['by_type']:
                        process_stats['by_type'][logic_type] = {
                            'start_time': time.time(),
                            'files_count': 0,
                            'successful_files': 0,
                            'failed_files': 0,
                            'errors': [],
                            'individual_processing_time': 0  # ‡πÄ‡∏Å‡πá‡∏ö‡πÄ‡∏ß‡∏•‡∏≤‡∏£‡∏ß‡∏°‡∏Ç‡∏≠‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ô‡∏µ‡πâ
                        }
                    
                    # ‡∏à‡∏±‡∏ö‡πÄ‡∏ß‡∏•‡∏≤‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ô‡∏µ‡πâ‡πÄ‡∏â‡∏û‡∏≤‡∏∞
                    file_start_time = time.time()
                    
                    process_stats['by_type'][logic_type]['files_count'] += 1
                    
                    self.log(f"üìã Identified file type: {logic_type}")
                    
                    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏Å‡πà‡∏≠‡∏ô‡πÇ‡∏î‡∏¢‡∏Å‡∏≤‡∏£ preview ‡πÑ‡∏ü‡∏•‡πå (‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î‡πÄ‡∏ß‡∏•‡∏≤)
                    success, result, columns_info = self.file_service.preview_file_columns(file_path, logic_type)
                    if not success:
                        error_msg = f"Column check failed: {result}"
                        self.log(f"‚ùå {error_msg}")
                        process_stats['by_type'][logic_type]['failed_files'] += 1
                        process_stats['by_type'][logic_type]['errors'].append(f"{os.path.basename(file_path)}: {error_msg}")
                        process_stats['failed_files'] += 1
                        
                        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÅ‡∏°‡πâ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß
                        file_processing_time = time.time() - file_start_time
                        process_stats['by_type'][logic_type]['individual_processing_time'] += file_processing_time
                        continue
                    
                    # ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏ï‡πá‡∏°‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö (‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ú‡πà‡∏≤‡∏ô‡πÅ‡∏•‡πâ‡∏ß)
                    success, result = self.file_service.read_excel_file(file_path, logic_type)
                    if not success:
                        error_msg = f"Could not read file: {result}"
                        self.log(f"‚ùå {error_msg}")
                        process_stats['by_type'][logic_type]['failed_files'] += 1
                        process_stats['by_type'][logic_type]['errors'].append(f"{os.path.basename(file_path)}: {error_msg}")
                        process_stats['failed_files'] += 1
                        
                        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÅ‡∏°‡πâ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß
                        file_processing_time = time.time() - file_start_time
                        process_stats['by_type'][logic_type]['individual_processing_time'] += file_processing_time
                        continue
                    
                    df = result
                    
                    # ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏: ‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏à‡∏∞‡∏ó‡∏≥‡πÉ‡∏ô staging table ‡∏î‡πâ‡∏ß‡∏¢ SQL
                    
                    # ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
                    required_cols = self.file_service.get_required_dtypes(logic_type)
                    
                    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ required_cols ‡πÑ‡∏°‡πà‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏õ‡∏•‡πà‡∏≤
                    if not required_cols:
                        error_msg = f"No data type configuration found for {logic_type}"
                        self.log(f"‚ùå {error_msg}")
                        process_stats['by_type'][logic_type]['failed_files'] += 1
                        process_stats['by_type'][logic_type]['errors'].append(f"{os.path.basename(file_path)}: {error_msg}")
                        process_stats['failed_files'] += 1
                        
                        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÅ‡∏°‡πâ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡∏û‡∏ö configuration
                        file_processing_time = time.time() - file_start_time
                        process_stats['by_type'][logic_type]['individual_processing_time'] += file_processing_time
                        continue
                    
                    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏õ‡∏•‡πà‡∏≤
                    if df.empty:
                        error_msg = f"File {os.path.basename(file_path)} has no data"
                        self.log(f"‚ùå {error_msg}")
                        process_stats['by_type'][logic_type]['failed_files'] += 1
                        process_stats['by_type'][logic_type]['errors'].append(f"{os.path.basename(file_path)}: {error_msg}")
                        process_stats['failed_files'] += 1
                        
                        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÅ‡∏°‡πâ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏õ‡∏•‡πà‡∏≤
                        file_processing_time = time.time() - file_start_time
                        process_stats['by_type'][logic_type]['individual_processing_time'] += file_processing_time
                        continue
                    
                    self.log(f"üìä Uploading {len(df)} rows for type {logic_type}")
                    # Clear existing data on first upload for each type
                    success, message = self.db_service.upload_data(df, logic_type, required_cols, log_func=self.log, clear_existing=True)
                    
                    if success:
                        self.log(f"‚úÖ Upload successful: {message}")
                        successful_uploads += 1
                        process_stats['by_type'][logic_type]['successful_files'] += 1
                        process_stats['successful_files'] += 1
                        
                        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ô‡∏µ‡πâ‡πÅ‡∏•‡∏∞‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡πÉ‡∏ô‡πÄ‡∏ß‡∏•‡∏≤‡∏£‡∏ß‡∏°
                        file_processing_time = time.time() - file_start_time
                        process_stats['by_type'][logic_type]['individual_processing_time'] += file_processing_time
                        
                        # ‡∏¢‡πâ‡∏≤‡∏¢‡πÑ‡∏ü‡∏•‡πå‡∏´‡∏•‡∏±‡∏á‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à
                        try:
                            move_success, move_result = self.file_service.move_uploaded_files([file_path], [logic_type])
                            if move_success:
                                for original_path, new_path in move_result:
                                    self.log(f"üì¶ Moved file to: {os.path.basename(new_path)}")
                            else:
                                self.log(f"‚ùå Could not move file: {move_result}")
                        except Exception as move_error:
                            self.log(f"‚ùå An error occurred while moving file: {move_error}")
                    else:
                        # ‡πÅ‡∏™‡∏î‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏£‡∏∏‡∏õ‡∏à‡∏≤‡∏Å‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡πÑ‡∏°‡πà‡∏û‡∏¥‡∏°‡∏û‡πå‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
                        error_msg = f"Upload failed: {message}"
                        self.log(f"‚ùå {error_msg}")
                        process_stats['by_type'][logic_type]['failed_files'] += 1
                        process_stats['by_type'][logic_type]['errors'].append(f"{os.path.basename(file_path)}: {error_msg}")
                        process_stats['failed_files'] += 1
                        
                        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ô‡∏µ‡πâ‡πÅ‡∏°‡πâ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß
                        file_processing_time = time.time() - file_start_time
                        process_stats['by_type'][logic_type]['individual_processing_time'] += file_processing_time
                        
                except Exception as e:
                    error_msg = f"An error occurred while processing {os.path.basename(file_path)}: {e}"
                    self.log(f"‚ùå {error_msg}")
                    if logic_type and logic_type in process_stats['by_type']:
                        process_stats['by_type'][logic_type]['failed_files'] += 1
                        process_stats['by_type'][logic_type]['errors'].append(f"{os.path.basename(file_path)}: {str(e)}")
                        
                        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ô‡∏µ‡πâ‡πÅ‡∏°‡πâ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î
                        file_processing_time = time.time() - file_start_time
                        process_stats['by_type'][logic_type]['individual_processing_time'] += file_processing_time
                    process_stats['failed_files'] += 1
            
            # ‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤‡∏£‡∏ß‡∏°‡∏ó‡∏µ‡πà‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÅ‡∏¢‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó
            for logic_type in process_stats['by_type']:
                if 'individual_processing_time' in process_stats['by_type'][logic_type]:
                    process_stats['by_type'][logic_type]['processing_time'] = process_stats['by_type'][logic_type]['individual_processing_time']
            
            # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÄ‡∏ß‡∏•‡∏≤‡∏£‡∏ß‡∏°
            process_stats['total_time'] = time.time() - process_start_time
            
            # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï progress ‡πÄ‡∏õ‡πá‡∏ô 100% ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô
            ui_callbacks['update_progress'](1.0, "Processing completed", f"Successfully processed {successful_uploads} of {total_files} files")
            
            # ‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏™‡∏£‡∏∏‡∏õ
            self._display_auto_process_summary(process_stats, total_files)
            
            # ‡∏•‡πâ‡∏≤‡∏á list ‡πÑ‡∏ü‡∏•‡πå‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÄ‡∏™‡∏£‡πá‡∏à ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏õ‡∏Å‡∏ï‡∏¥
            ui_callbacks['clear_file_list']()
            ui_callbacks['reset_select_all']()
            
        except Exception as e:
            self.log(f"‚ùå An error occurred while processing files: {e}")
